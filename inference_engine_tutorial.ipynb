{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ingramai/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.6 of module 'openvino.inference_engine.ie_api' does not match runtime version 3.7\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from openvino.inference_engine import IECore, IENetwork\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model to the Inference Engine\n",
    "\n",
    "def load_model(xml_file, bin_file):\n",
    "    \n",
    "    #xml_file = args.xml\n",
    "    \n",
    "    #bin_file = args.bin\n",
    "    \n",
    "    core = IECore()   #create an instance of the inference engine\n",
    "    \n",
    "    network = IENetwork(model=xml_file, weights=bin_file)\n",
    "    \n",
    "    # check if any of the network layers is not supported for the target hardware:\n",
    "    \n",
    "    suppoted_layers = core.query_network(network = network, device_name = 'CPU') # get supported layers\n",
    "    \n",
    "    unsupported_layers = [layer for layer in network.layers.keys() if layer not in suppoted_layers] # get unsupported layers\n",
    "    \n",
    "    if len(unsupported_layers) == 0:\n",
    "        \n",
    "        print('All network layers are supported!')\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        print('Those layers are not supported, please add extensions for them', unsupported_layers)\n",
    "        \n",
    "    exec_network = core.load_network(network, 'CPU') # load the network to the engine\n",
    "    \n",
    "    input_layer = next(iter(network.inputs))   # get input layer of the network\n",
    "    \n",
    "    input_shape = network.inputs[input_layer].shape  # get input shape for preprocessing\n",
    "        \n",
    "    return exec_network, input_shape\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(image, input_shape):\n",
    "    im = np.copy(image)\n",
    "    im = cv2.resize(im, (input_shape[2], input_shape[3]))\n",
    "    im = im.transpose((2,0,1))\n",
    "    im = im.reshape(1,*im.shape)\n",
    "    \n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sync_inference(executable_network, inputs):\n",
    "    \n",
    "    outputs = executable_network.infer(inputs)\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def async_inference(executable_network, inputs):\n",
    "    \n",
    "    handler = executable_network.start_async(0, inputs) \n",
    "    \n",
    "    handler.wait(-1)\n",
    "    \n",
    "    outputs = handler.outputs\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All network layers are supported!\n",
      "sync inference done!: neutral\n",
      "Async inference done!: neutral\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread('input.jpeg')\n",
    "\n",
    "emotions = ['neutral', 'happy', 'sad', 'surprise', 'anger']\n",
    "\n",
    "exec_net, input_shape = load_model('intel/emotions-recognition-retail-0003/FP32/emotions-recognition-retail-0003.xml', \n",
    "                      'intel/emotions-recognition-retail-0003/FP32/emotions-recognition-retail-0003.bin')\n",
    "\n",
    "im = preprocessing(image, input_shape)\n",
    "\n",
    "input_layer = next(iter(exec_net.inputs))\n",
    "\n",
    "inputs = {input_layer: im}\n",
    "\n",
    "sync_output = sync_inference(exec_net, inputs)\n",
    "\n",
    "emotion = np.argmax(sync_output)\n",
    "\n",
    "emotion = emotions[emotion]\n",
    "\n",
    "print('sync inference done!:', emotion)\n",
    "\n",
    "async_ouput = async_inference(exec_net, inputs)\n",
    "                   \n",
    "emotion = np.argmax(async_ouput)\n",
    "\n",
    "emotion = emotions[emotion]\n",
    "\n",
    "print('Async inference done!:', emotion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
